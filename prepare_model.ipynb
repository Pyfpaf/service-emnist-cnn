{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3879",
   "metadata": {},
   "source": [
    "# Подготовка модели распознавания рукописных букв и цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a8c2194-872a-4ce3-8da7-48f7555b82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchvision torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5717e55d-fa0a-450a-a584-01f6f5e0ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from torchvision.datasets import EMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17fa0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EMNIST('data/', 'balanced', train=True, download=False)\n",
    "val_dataset = EMNIST('data/', 'balanced', train=False, download=False)\n",
    "\n",
    "with open('emnist-balanced-mapping.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "lines = content.strip().split('\\n')\n",
    "labels_dict = {int(lines[i].split(' ')[0]): chr(int(lines[i].split(' ')[1])) for i in range(len(lines))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b07cb352-cc20-469a-87d6-d4099373e56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(20, 12))\n",
    "\n",
    "rand_numbers = [random.randint(1, 112800) for _ in range(5)]\n",
    "for i in range(5):\n",
    "    ax[i].imshow(train_dataset[rand_numbers[i]][0], cmap='gray')\n",
    "    ax[i].set_title(f'Символ {labels_dict[train_dataset[rand_numbers[i]][1]]}')\n",
    "    ax[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c3984ea-23c3-47b8-8036-bf57148e82be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.5], [0.5])\n",
    "])\n",
    "train_dataset = EMNIST('data/', 'balanced', train=True, download=False, transform=transform)\n",
    "val_dataset = EMNIST('data/', 'balanced', train=False, download=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "084078b8-a43a-4e74-8ef6-03b0ac26f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes=47):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, (3, 3), padding=1), #(batch_size, 1, 28, 28) -> (batch_size, 32, 28, 28)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), #(batch_size, 1, 28, 28) -> (batch_size, 32, 14, 14)\n",
    "            nn.Conv2d(32, 64, (3, 3)), #(batch_size, 32, 14, 14) -> (batch_size, 64, 12, 12)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), #(batch_size, 64, 12, 12) -> (batch_size, 64, 6, 6)\n",
    "            nn.Flatten(), #(batch_size, 64, 6, 6) -> (batch_size, 64*6*6)\n",
    "            nn.Linear(64*6*6, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        return self.model(x)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85617c21-6044-4e99-b74e-5836903ff9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, n_epoch, val_fre):\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        loss_sum = 0\n",
    "        print(f'Epoch: {epoch}')\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f'Iter: {step} \\tLoss: {loss.item()}')\n",
    "\n",
    "        print(f'Mean Train Loss: {loss_sum / (step + 1):.6f}', end='\\n\\n')\n",
    "\n",
    "        if epoch % val_fre == 0:\n",
    "            validate(model, val_loader, epoch)\n",
    "\n",
    "def validate(model, val_loader, epoch):\n",
    "        \n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    for step, (data, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(data).squeeze(1)\n",
    "            loss = loss_fn(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    \n",
    "    mean_val_loss = loss_sum / (step + 1)\n",
    "    \n",
    "    if epoch > 19:\n",
    "        torch.save(model.state_dict(), f'myapp/cnn_epoch_{epoch}.pth')\n",
    "        print(f'На эпохе {epoch} параметры модели были сохранены при наилучшем значении функции потерь {mean_val_loss:.6f} на валидационной выборке.')\n",
    "        print(f'Метрика Accuracy: {acc:.4f}.')\n",
    "    else:    \n",
    "        print(f'Функция потерь: {mean_val_loss:.6f} \\tМетрика Accuracy: {acc:.4f}')\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a53bfe05-acda-4f48-a4d8-e3cda25cfeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(clf.parameters(), lr=0.0001)\n",
    "n_epoch = 50\n",
    "val_fre = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2c58e9b9-41f8-4da1-9f52-3df3d956bf52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Iter: 0 \tLoss: 3.8641529083251953\n",
      "Iter: 10 \tLoss: 3.6765568256378174\n",
      "Iter: 20 \tLoss: 3.436800003051758\n",
      "Iter: 30 \tLoss: 3.164767026901245\n",
      "Iter: 40 \tLoss: 2.829808235168457\n",
      "Iter: 50 \tLoss: 2.48492693901062\n",
      "Iter: 60 \tLoss: 2.162473440170288\n",
      "Iter: 70 \tLoss: 1.9471747875213623\n",
      "Iter: 80 \tLoss: 1.7833251953125\n",
      "Iter: 90 \tLoss: 1.5572558641433716\n",
      "Iter: 100 \tLoss: 1.4266886711120605\n",
      "Iter: 110 \tLoss: 1.1132619380950928\n",
      "Mean Train Loss: 2.464007\n",
      "\n",
      "Epoch: 2\n",
      "Iter: 0 \tLoss: 1.3245621919631958\n",
      "Iter: 10 \tLoss: 1.2456772327423096\n",
      "Iter: 20 \tLoss: 1.246539831161499\n",
      "Iter: 30 \tLoss: 1.0912902355194092\n",
      "Iter: 40 \tLoss: 1.0607794523239136\n",
      "Iter: 50 \tLoss: 1.0026299953460693\n",
      "Iter: 60 \tLoss: 0.9868945479393005\n",
      "Iter: 70 \tLoss: 0.9472066760063171\n",
      "Iter: 80 \tLoss: 0.9264494776725769\n",
      "Iter: 90 \tLoss: 0.8692208528518677\n",
      "Iter: 100 \tLoss: 0.8750441670417786\n",
      "Iter: 110 \tLoss: 0.8021543622016907\n",
      "Mean Train Loss: 1.034585\n",
      "\n",
      "Функция потерь: 0.719629 \tМетрика Accuracy: 0.7872\n",
      "Epoch: 3\n",
      "Iter: 0 \tLoss: 0.8885976076126099\n",
      "Iter: 10 \tLoss: 0.7640771269798279\n",
      "Iter: 20 \tLoss: 0.8295771479606628\n",
      "Iter: 30 \tLoss: 0.7847914099693298\n",
      "Iter: 40 \tLoss: 0.7428640127182007\n",
      "Iter: 50 \tLoss: 0.7912518978118896\n",
      "Iter: 60 \tLoss: 0.6435830593109131\n",
      "Iter: 70 \tLoss: 0.7139964699745178\n",
      "Iter: 80 \tLoss: 0.7689910531044006\n",
      "Iter: 90 \tLoss: 0.7064266204833984\n",
      "Iter: 100 \tLoss: 0.6907918453216553\n",
      "Iter: 110 \tLoss: 0.6348622441291809\n",
      "Mean Train Loss: 0.755423\n",
      "\n",
      "Epoch: 4\n",
      "Iter: 0 \tLoss: 0.6655968427658081\n",
      "Iter: 10 \tLoss: 0.6587027907371521\n",
      "Iter: 20 \tLoss: 0.6361966133117676\n",
      "Iter: 30 \tLoss: 0.5958095192909241\n",
      "Iter: 40 \tLoss: 0.6665186882019043\n",
      "Iter: 50 \tLoss: 0.5975770354270935\n",
      "Iter: 60 \tLoss: 0.6651577353477478\n",
      "Iter: 70 \tLoss: 0.6273143887519836\n",
      "Iter: 80 \tLoss: 0.6127034425735474\n",
      "Iter: 90 \tLoss: 0.6734007596969604\n",
      "Iter: 100 \tLoss: 0.6110053658485413\n",
      "Iter: 110 \tLoss: 0.7165507078170776\n",
      "Mean Train Loss: 0.640292\n",
      "\n",
      "Функция потерь: 0.534266 \tМетрика Accuracy: 0.8327\n",
      "Epoch: 5\n",
      "Iter: 0 \tLoss: 0.6064465641975403\n",
      "Iter: 10 \tLoss: 0.6218889951705933\n",
      "Iter: 20 \tLoss: 0.5393303632736206\n",
      "Iter: 30 \tLoss: 0.5925622582435608\n",
      "Iter: 40 \tLoss: 0.5864461064338684\n",
      "Iter: 50 \tLoss: 0.5818910002708435\n",
      "Iter: 60 \tLoss: 0.5129036903381348\n",
      "Iter: 70 \tLoss: 0.6067556738853455\n",
      "Iter: 80 \tLoss: 0.6125984787940979\n",
      "Iter: 90 \tLoss: 0.5995174646377563\n",
      "Iter: 100 \tLoss: 0.5177258253097534\n",
      "Iter: 110 \tLoss: 0.5019006729125977\n",
      "Mean Train Loss: 0.573685\n",
      "\n",
      "Epoch: 6\n",
      "Iter: 0 \tLoss: 0.6039348840713501\n",
      "Iter: 10 \tLoss: 0.5366815328598022\n",
      "Iter: 20 \tLoss: 0.5386871099472046\n",
      "Iter: 30 \tLoss: 0.5390682816505432\n",
      "Iter: 40 \tLoss: 0.5696561336517334\n",
      "Iter: 50 \tLoss: 0.5497578382492065\n",
      "Iter: 60 \tLoss: 0.5389760136604309\n",
      "Iter: 70 \tLoss: 0.5081254243850708\n",
      "Iter: 80 \tLoss: 0.49775490164756775\n",
      "Iter: 90 \tLoss: 0.5365731716156006\n",
      "Iter: 100 \tLoss: 0.49405255913734436\n",
      "Iter: 110 \tLoss: 0.544687807559967\n",
      "Mean Train Loss: 0.533301\n",
      "\n",
      "Функция потерь: 0.470493 \tМетрика Accuracy: 0.8472\n",
      "Epoch: 7\n",
      "Iter: 0 \tLoss: 0.5326701402664185\n",
      "Iter: 10 \tLoss: 0.5372607111930847\n",
      "Iter: 20 \tLoss: 0.5513875484466553\n",
      "Iter: 30 \tLoss: 0.5144487619400024\n",
      "Iter: 40 \tLoss: 0.5018624663352966\n",
      "Iter: 50 \tLoss: 0.4718339741230011\n",
      "Iter: 60 \tLoss: 0.47497302293777466\n",
      "Iter: 70 \tLoss: 0.5053489208221436\n",
      "Iter: 80 \tLoss: 0.5034198760986328\n",
      "Iter: 90 \tLoss: 0.4978983700275421\n",
      "Iter: 100 \tLoss: 0.48271772265434265\n",
      "Iter: 110 \tLoss: 0.5054084062576294\n",
      "Mean Train Loss: 0.499613\n",
      "\n",
      "Epoch: 8\n",
      "Iter: 0 \tLoss: 0.4892862141132355\n",
      "Iter: 10 \tLoss: 0.42709511518478394\n",
      "Iter: 20 \tLoss: 0.45937246084213257\n",
      "Iter: 30 \tLoss: 0.5083853006362915\n",
      "Iter: 40 \tLoss: 0.4835963249206543\n",
      "Iter: 50 \tLoss: 0.4852689206600189\n",
      "Iter: 60 \tLoss: 0.45883482694625854\n",
      "Iter: 70 \tLoss: 0.4460785686969757\n",
      "Iter: 80 \tLoss: 0.4105754494667053\n",
      "Iter: 90 \tLoss: 0.46274030208587646\n",
      "Iter: 100 \tLoss: 0.4780670702457428\n",
      "Iter: 110 \tLoss: 0.467425674200058\n",
      "Mean Train Loss: 0.473063\n",
      "\n",
      "Функция потерь: 0.433431 \tМетрика Accuracy: 0.8550\n",
      "Epoch: 9\n",
      "Iter: 0 \tLoss: 0.46017125248908997\n",
      "Iter: 10 \tLoss: 0.46912798285484314\n",
      "Iter: 20 \tLoss: 0.4481256306171417\n",
      "Iter: 30 \tLoss: 0.4028015434741974\n",
      "Iter: 40 \tLoss: 0.42837607860565186\n",
      "Iter: 50 \tLoss: 0.4320746064186096\n",
      "Iter: 60 \tLoss: 0.4860009253025055\n",
      "Iter: 70 \tLoss: 0.46921563148498535\n",
      "Iter: 80 \tLoss: 0.49462294578552246\n",
      "Iter: 90 \tLoss: 0.4881379306316376\n",
      "Iter: 100 \tLoss: 0.47055235505104065\n",
      "Iter: 110 \tLoss: 0.3775792419910431\n",
      "Mean Train Loss: 0.454199\n",
      "\n",
      "Epoch: 10\n",
      "Iter: 0 \tLoss: 0.4688282012939453\n",
      "Iter: 10 \tLoss: 0.5067527294158936\n",
      "Iter: 20 \tLoss: 0.42091861367225647\n",
      "Iter: 30 \tLoss: 0.4033389985561371\n",
      "Iter: 40 \tLoss: 0.4096774458885193\n",
      "Iter: 50 \tLoss: 0.4266006052494049\n",
      "Iter: 60 \tLoss: 0.4587676525115967\n",
      "Iter: 70 \tLoss: 0.45100802183151245\n",
      "Iter: 80 \tLoss: 0.48225098848342896\n",
      "Iter: 90 \tLoss: 0.4368426203727722\n",
      "Iter: 100 \tLoss: 0.4464286267757416\n",
      "Iter: 110 \tLoss: 0.5309179425239563\n",
      "Mean Train Loss: 0.439732\n",
      "\n",
      "Функция потерь: 0.409438 \tМетрика Accuracy: 0.8593\n",
      "Epoch: 11\n",
      "Iter: 0 \tLoss: 0.4648120105266571\n",
      "Iter: 10 \tLoss: 0.4145742356777191\n",
      "Iter: 20 \tLoss: 0.4413248598575592\n",
      "Iter: 30 \tLoss: 0.43181222677230835\n",
      "Iter: 40 \tLoss: 0.46261781454086304\n",
      "Iter: 50 \tLoss: 0.4062345623970032\n",
      "Iter: 60 \tLoss: 0.3783233165740967\n",
      "Iter: 70 \tLoss: 0.4221777617931366\n",
      "Iter: 80 \tLoss: 0.4412049651145935\n",
      "Iter: 90 \tLoss: 0.34760966897010803\n",
      "Iter: 100 \tLoss: 0.38926711678504944\n",
      "Iter: 110 \tLoss: 0.5081343650817871\n",
      "Mean Train Loss: 0.423778\n",
      "\n",
      "Epoch: 12\n",
      "Iter: 0 \tLoss: 0.3756055533885956\n",
      "Iter: 10 \tLoss: 0.407836377620697\n",
      "Iter: 20 \tLoss: 0.37911367416381836\n",
      "Iter: 30 \tLoss: 0.4212813675403595\n",
      "Iter: 40 \tLoss: 0.34483957290649414\n",
      "Iter: 50 \tLoss: 0.4420853853225708\n",
      "Iter: 60 \tLoss: 0.3640613257884979\n",
      "Iter: 70 \tLoss: 0.3797241449356079\n",
      "Iter: 80 \tLoss: 0.4067300260066986\n",
      "Iter: 90 \tLoss: 0.42738351225852966\n",
      "Iter: 100 \tLoss: 0.41528475284576416\n",
      "Iter: 110 \tLoss: 0.3867378830909729\n",
      "Mean Train Loss: 0.412051\n",
      "\n",
      "Функция потерь: 0.393429 \tМетрика Accuracy: 0.8656\n",
      "Epoch: 13\n",
      "Iter: 0 \tLoss: 0.3893536925315857\n",
      "Iter: 10 \tLoss: 0.3705027401447296\n",
      "Iter: 20 \tLoss: 0.416645884513855\n",
      "Iter: 30 \tLoss: 0.3789130747318268\n",
      "Iter: 40 \tLoss: 0.43871983885765076\n",
      "Iter: 50 \tLoss: 0.36202430725097656\n",
      "Iter: 60 \tLoss: 0.45291706919670105\n",
      "Iter: 70 \tLoss: 0.44821813702583313\n",
      "Iter: 80 \tLoss: 0.37856075167655945\n",
      "Iter: 90 \tLoss: 0.38877546787261963\n",
      "Iter: 100 \tLoss: 0.3787851929664612\n",
      "Iter: 110 \tLoss: 0.5546354055404663\n",
      "Mean Train Loss: 0.404001\n",
      "\n",
      "Epoch: 14\n",
      "Iter: 0 \tLoss: 0.35158950090408325\n",
      "Iter: 10 \tLoss: 0.41771769523620605\n",
      "Iter: 20 \tLoss: 0.3603880703449249\n",
      "Iter: 30 \tLoss: 0.33730795979499817\n",
      "Iter: 40 \tLoss: 0.4067082703113556\n",
      "Iter: 50 \tLoss: 0.40163058042526245\n",
      "Iter: 60 \tLoss: 0.41451188921928406\n",
      "Iter: 70 \tLoss: 0.40099164843559265\n",
      "Iter: 80 \tLoss: 0.34904661774635315\n",
      "Iter: 90 \tLoss: 0.3936832845211029\n",
      "Iter: 100 \tLoss: 0.4526613652706146\n",
      "Iter: 110 \tLoss: 0.49004989862442017\n",
      "Mean Train Loss: 0.391589\n",
      "\n",
      "Функция потерь: 0.382186 \tМетрика Accuracy: 0.8683\n",
      "Epoch: 15\n",
      "Iter: 0 \tLoss: 0.3773285746574402\n",
      "Iter: 10 \tLoss: 0.39924871921539307\n",
      "Iter: 20 \tLoss: 0.35194650292396545\n",
      "Iter: 30 \tLoss: 0.361710786819458\n",
      "Iter: 40 \tLoss: 0.40272435545921326\n",
      "Iter: 50 \tLoss: 0.40604910254478455\n",
      "Iter: 60 \tLoss: 0.4156232178211212\n",
      "Iter: 70 \tLoss: 0.3680228292942047\n",
      "Iter: 80 \tLoss: 0.38516420125961304\n",
      "Iter: 90 \tLoss: 0.33692681789398193\n",
      "Iter: 100 \tLoss: 0.392894446849823\n",
      "Iter: 110 \tLoss: 0.46067243814468384\n",
      "Mean Train Loss: 0.382371\n",
      "\n",
      "Epoch: 16\n",
      "Iter: 0 \tLoss: 0.36307114362716675\n",
      "Iter: 10 \tLoss: 0.3639930188655853\n",
      "Iter: 20 \tLoss: 0.3675319254398346\n",
      "Iter: 30 \tLoss: 0.35747048258781433\n",
      "Iter: 40 \tLoss: 0.33727818727493286\n",
      "Iter: 50 \tLoss: 0.362385630607605\n",
      "Iter: 60 \tLoss: 0.3772223889827728\n",
      "Iter: 70 \tLoss: 0.37278079986572266\n",
      "Iter: 80 \tLoss: 0.37533050775527954\n",
      "Iter: 90 \tLoss: 0.3720536530017853\n",
      "Iter: 100 \tLoss: 0.37815365195274353\n",
      "Iter: 110 \tLoss: 0.36989858746528625\n",
      "Mean Train Loss: 0.371849\n",
      "\n",
      "Функция потерь: 0.370361 \tМетрика Accuracy: 0.8706\n",
      "Epoch: 17\n",
      "Iter: 0 \tLoss: 0.3335443437099457\n",
      "Iter: 10 \tLoss: 0.32400867342948914\n",
      "Iter: 20 \tLoss: 0.3579859137535095\n",
      "Iter: 30 \tLoss: 0.38241884112358093\n",
      "Iter: 40 \tLoss: 0.35683855414390564\n",
      "Iter: 50 \tLoss: 0.3634389340877533\n",
      "Iter: 60 \tLoss: 0.35942986607551575\n",
      "Iter: 70 \tLoss: 0.370024710893631\n",
      "Iter: 80 \tLoss: 0.3772100508213043\n",
      "Iter: 90 \tLoss: 0.4374445080757141\n",
      "Iter: 100 \tLoss: 0.4043858051300049\n",
      "Iter: 110 \tLoss: 0.5555324554443359\n",
      "Mean Train Loss: 0.367831\n",
      "\n",
      "Epoch: 18\n",
      "Iter: 0 \tLoss: 0.3803154528141022\n",
      "Iter: 10 \tLoss: 0.3459829092025757\n",
      "Iter: 20 \tLoss: 0.3962341547012329\n",
      "Iter: 30 \tLoss: 0.4279041290283203\n",
      "Iter: 40 \tLoss: 0.3899940550327301\n",
      "Iter: 50 \tLoss: 0.3456762731075287\n",
      "Iter: 60 \tLoss: 0.3532632887363434\n",
      "Iter: 70 \tLoss: 0.33800026774406433\n",
      "Iter: 80 \tLoss: 0.38093703985214233\n",
      "Iter: 90 \tLoss: 0.31847938895225525\n",
      "Iter: 100 \tLoss: 0.34476494789123535\n",
      "Iter: 110 \tLoss: 0.3617230951786041\n",
      "Mean Train Loss: 0.359653\n",
      "\n",
      "Функция потерь: 0.362503 \tМетрика Accuracy: 0.8740\n",
      "Epoch: 19\n",
      "Iter: 0 \tLoss: 0.37221887707710266\n",
      "Iter: 10 \tLoss: 0.35573050379753113\n",
      "Iter: 20 \tLoss: 0.33463433384895325\n",
      "Iter: 30 \tLoss: 0.31667423248291016\n",
      "Iter: 40 \tLoss: 0.3771848678588867\n",
      "Iter: 50 \tLoss: 0.35911017656326294\n",
      "Iter: 60 \tLoss: 0.3151633143424988\n",
      "Iter: 70 \tLoss: 0.3869017958641052\n",
      "Iter: 80 \tLoss: 0.34352484345436096\n",
      "Iter: 90 \tLoss: 0.35114479064941406\n",
      "Iter: 100 \tLoss: 0.36602717638015747\n",
      "Iter: 110 \tLoss: 0.3485400080680847\n",
      "Mean Train Loss: 0.351527\n",
      "\n",
      "Epoch: 20\n",
      "Iter: 0 \tLoss: 0.32188305258750916\n",
      "Iter: 10 \tLoss: 0.32072868943214417\n",
      "Iter: 20 \tLoss: 0.32686883211135864\n",
      "Iter: 30 \tLoss: 0.34273087978363037\n",
      "Iter: 40 \tLoss: 0.3519919216632843\n",
      "Iter: 50 \tLoss: 0.3568164110183716\n",
      "Iter: 60 \tLoss: 0.3429297208786011\n",
      "Iter: 70 \tLoss: 0.3163238763809204\n",
      "Iter: 80 \tLoss: 0.33546754717826843\n",
      "Iter: 90 \tLoss: 0.3563120365142822\n",
      "Iter: 100 \tLoss: 0.3218834400177002\n",
      "Iter: 110 \tLoss: 0.3788389265537262\n",
      "Mean Train Loss: 0.345988\n",
      "\n",
      "На эпохе 20 параметры модели были сохранены при наилучшем значении функции потерь 0.357718 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8752.\n",
      "Epoch: 21\n",
      "Iter: 0 \tLoss: 0.29840007424354553\n",
      "Iter: 10 \tLoss: 0.3354812562465668\n",
      "Iter: 20 \tLoss: 0.343718022108078\n",
      "Iter: 30 \tLoss: 0.3438994884490967\n",
      "Iter: 40 \tLoss: 0.36054426431655884\n",
      "Iter: 50 \tLoss: 0.3098270893096924\n",
      "Iter: 60 \tLoss: 0.3215042054653168\n",
      "Iter: 70 \tLoss: 0.3034036457538605\n",
      "Iter: 80 \tLoss: 0.36778518557548523\n",
      "Iter: 90 \tLoss: 0.31723320484161377\n",
      "Iter: 100 \tLoss: 0.36322206258773804\n",
      "Iter: 110 \tLoss: 0.54119473695755\n",
      "Mean Train Loss: 0.341379\n",
      "\n",
      "Epoch: 22\n",
      "Iter: 0 \tLoss: 0.3564382791519165\n",
      "Iter: 10 \tLoss: 0.357600599527359\n",
      "Iter: 20 \tLoss: 0.3267594575881958\n",
      "Iter: 30 \tLoss: 0.34776124358177185\n",
      "Iter: 40 \tLoss: 0.33197644352912903\n",
      "Iter: 50 \tLoss: 0.3666684627532959\n",
      "Iter: 60 \tLoss: 0.35568687319755554\n",
      "Iter: 70 \tLoss: 0.2874842584133148\n",
      "Iter: 80 \tLoss: 0.3214370608329773\n",
      "Iter: 90 \tLoss: 0.31685611605644226\n",
      "Iter: 100 \tLoss: 0.2818824350833893\n",
      "Iter: 110 \tLoss: 0.31994420289993286\n",
      "Mean Train Loss: 0.334846\n",
      "\n",
      "На эпохе 22 параметры модели были сохранены при наилучшем значении функции потерь 0.350424 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8769.\n",
      "Epoch: 23\n",
      "Iter: 0 \tLoss: 0.34295305609703064\n",
      "Iter: 10 \tLoss: 0.3025173842906952\n",
      "Iter: 20 \tLoss: 0.3780071437358856\n",
      "Iter: 30 \tLoss: 0.32796430587768555\n",
      "Iter: 40 \tLoss: 0.34060919284820557\n",
      "Iter: 50 \tLoss: 0.37250009179115295\n",
      "Iter: 60 \tLoss: 0.3229753077030182\n",
      "Iter: 70 \tLoss: 0.34369415044784546\n",
      "Iter: 80 \tLoss: 0.28660789132118225\n",
      "Iter: 90 \tLoss: 0.2969805598258972\n",
      "Iter: 100 \tLoss: 0.3029697835445404\n",
      "Iter: 110 \tLoss: 0.30127274990081787\n",
      "Mean Train Loss: 0.329337\n",
      "\n",
      "Epoch: 24\n",
      "Iter: 0 \tLoss: 0.29708632826805115\n",
      "Iter: 10 \tLoss: 0.30075937509536743\n",
      "Iter: 20 \tLoss: 0.36529189348220825\n",
      "Iter: 30 \tLoss: 0.30506187677383423\n",
      "Iter: 40 \tLoss: 0.32674452662467957\n",
      "Iter: 50 \tLoss: 0.30778926610946655\n",
      "Iter: 60 \tLoss: 0.3333912193775177\n",
      "Iter: 70 \tLoss: 0.2923809885978699\n",
      "Iter: 80 \tLoss: 0.298918753862381\n",
      "Iter: 90 \tLoss: 0.3272223174571991\n",
      "Iter: 100 \tLoss: 0.305189847946167\n",
      "Iter: 110 \tLoss: 0.35123980045318604\n",
      "Mean Train Loss: 0.324798\n",
      "\n",
      "На эпохе 24 параметры модели были сохранены при наилучшем значении функции потерь 0.345712 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8794.\n",
      "Epoch: 25\n",
      "Iter: 0 \tLoss: 0.3245494067668915\n",
      "Iter: 10 \tLoss: 0.3393062949180603\n",
      "Iter: 20 \tLoss: 0.29858702421188354\n",
      "Iter: 30 \tLoss: 0.27824586629867554\n",
      "Iter: 40 \tLoss: 0.32184892892837524\n",
      "Iter: 50 \tLoss: 0.3118109703063965\n",
      "Iter: 60 \tLoss: 0.36535775661468506\n",
      "Iter: 70 \tLoss: 0.2949540317058563\n",
      "Iter: 80 \tLoss: 0.3343476355075836\n",
      "Iter: 90 \tLoss: 0.3049320578575134\n",
      "Iter: 100 \tLoss: 0.3412494659423828\n",
      "Iter: 110 \tLoss: 0.4090301990509033\n",
      "Mean Train Loss: 0.320515\n",
      "\n",
      "Epoch: 26\n",
      "Iter: 0 \tLoss: 0.29534077644348145\n",
      "Iter: 10 \tLoss: 0.291422039270401\n",
      "Iter: 20 \tLoss: 0.3021724224090576\n",
      "Iter: 30 \tLoss: 0.29457589983940125\n",
      "Iter: 40 \tLoss: 0.30992254614830017\n",
      "Iter: 50 \tLoss: 0.31708186864852905\n",
      "Iter: 60 \tLoss: 0.35869279503822327\n",
      "Iter: 70 \tLoss: 0.32148027420043945\n",
      "Iter: 80 \tLoss: 0.3599507510662079\n",
      "Iter: 90 \tLoss: 0.35294419527053833\n",
      "Iter: 100 \tLoss: 0.32459038496017456\n",
      "Iter: 110 \tLoss: 0.3457100987434387\n",
      "Mean Train Loss: 0.314659\n",
      "\n",
      "На эпохе 26 параметры модели были сохранены при наилучшем значении функции потерь 0.342660 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8790.\n",
      "Epoch: 27\n",
      "Iter: 0 \tLoss: 0.2956184446811676\n",
      "Iter: 10 \tLoss: 0.260691374540329\n",
      "Iter: 20 \tLoss: 0.27984318137168884\n",
      "Iter: 30 \tLoss: 0.3577658236026764\n",
      "Iter: 40 \tLoss: 0.28794416785240173\n",
      "Iter: 50 \tLoss: 0.3436397910118103\n",
      "Iter: 60 \tLoss: 0.2859470248222351\n",
      "Iter: 70 \tLoss: 0.30248555541038513\n",
      "Iter: 80 \tLoss: 0.26841381192207336\n",
      "Iter: 90 \tLoss: 0.26830771565437317\n",
      "Iter: 100 \tLoss: 0.2811700403690338\n",
      "Iter: 110 \tLoss: 0.3687988519668579\n",
      "Mean Train Loss: 0.311216\n",
      "\n",
      "Epoch: 28\n",
      "Iter: 0 \tLoss: 0.2930203676223755\n",
      "Iter: 10 \tLoss: 0.3214956521987915\n",
      "Iter: 20 \tLoss: 0.3055928349494934\n",
      "Iter: 30 \tLoss: 0.2691917419433594\n",
      "Iter: 40 \tLoss: 0.3098439574241638\n",
      "Iter: 50 \tLoss: 0.33974048495292664\n",
      "Iter: 60 \tLoss: 0.25779396295547485\n",
      "Iter: 70 \tLoss: 0.3184145390987396\n",
      "Iter: 80 \tLoss: 0.3229181468486786\n",
      "Iter: 90 \tLoss: 0.32251328229904175\n",
      "Iter: 100 \tLoss: 0.3216877281665802\n",
      "Iter: 110 \tLoss: 0.34081390500068665\n",
      "Mean Train Loss: 0.304994\n",
      "\n",
      "На эпохе 28 параметры модели были сохранены при наилучшем значении функции потерь 0.338459 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8816.\n",
      "Epoch: 29\n",
      "Iter: 0 \tLoss: 0.2978276014328003\n",
      "Iter: 10 \tLoss: 0.3029467463493347\n",
      "Iter: 20 \tLoss: 0.36135223507881165\n",
      "Iter: 30 \tLoss: 0.35025742650032043\n",
      "Iter: 40 \tLoss: 0.31862056255340576\n",
      "Iter: 50 \tLoss: 0.2735833525657654\n",
      "Iter: 60 \tLoss: 0.35325971245765686\n",
      "Iter: 70 \tLoss: 0.34822434186935425\n",
      "Iter: 80 \tLoss: 0.32338467240333557\n",
      "Iter: 90 \tLoss: 0.2921571135520935\n",
      "Iter: 100 \tLoss: 0.3292350769042969\n",
      "Iter: 110 \tLoss: 0.4305519461631775\n",
      "Mean Train Loss: 0.303248\n",
      "\n",
      "Epoch: 30\n",
      "Iter: 0 \tLoss: 0.31628862023353577\n",
      "Iter: 10 \tLoss: 0.2850438356399536\n",
      "Iter: 20 \tLoss: 0.3169632852077484\n",
      "Iter: 30 \tLoss: 0.30622249841690063\n",
      "Iter: 40 \tLoss: 0.3339466154575348\n",
      "Iter: 50 \tLoss: 0.2836231589317322\n",
      "Iter: 60 \tLoss: 0.33423173427581787\n",
      "Iter: 70 \tLoss: 0.33799517154693604\n",
      "Iter: 80 \tLoss: 0.2894965708255768\n",
      "Iter: 90 \tLoss: 0.264835923910141\n",
      "Iter: 100 \tLoss: 0.2813611328601837\n",
      "Iter: 110 \tLoss: 0.3753919303417206\n",
      "Mean Train Loss: 0.298507\n",
      "\n",
      "На эпохе 30 параметры модели были сохранены при наилучшем значении функции потерь 0.334532 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8833.\n",
      "Epoch: 31\n",
      "Iter: 0 \tLoss: 0.30088934302330017\n",
      "Iter: 10 \tLoss: 0.27702173590660095\n",
      "Iter: 20 \tLoss: 0.27598488330841064\n",
      "Iter: 30 \tLoss: 0.312621146440506\n",
      "Iter: 40 \tLoss: 0.3436133563518524\n",
      "Iter: 50 \tLoss: 0.28578436374664307\n",
      "Iter: 60 \tLoss: 0.26306819915771484\n",
      "Iter: 70 \tLoss: 0.2974708378314972\n",
      "Iter: 80 \tLoss: 0.2733994722366333\n",
      "Iter: 90 \tLoss: 0.2841605246067047\n",
      "Iter: 100 \tLoss: 0.3018576502799988\n",
      "Iter: 110 \tLoss: 0.28670698404312134\n",
      "Mean Train Loss: 0.296506\n",
      "\n",
      "Epoch: 32\n",
      "Iter: 0 \tLoss: 0.3148755729198456\n",
      "Iter: 10 \tLoss: 0.28766971826553345\n",
      "Iter: 20 \tLoss: 0.2989285886287689\n",
      "Iter: 30 \tLoss: 0.3053399324417114\n",
      "Iter: 40 \tLoss: 0.2984749674797058\n",
      "Iter: 50 \tLoss: 0.2849348187446594\n",
      "Iter: 60 \tLoss: 0.2518022954463959\n",
      "Iter: 70 \tLoss: 0.3075961470603943\n",
      "Iter: 80 \tLoss: 0.32678157091140747\n",
      "Iter: 90 \tLoss: 0.2928311228752136\n",
      "Iter: 100 \tLoss: 0.30247655510902405\n",
      "Iter: 110 \tLoss: 0.29439443349838257\n",
      "Mean Train Loss: 0.290026\n",
      "\n",
      "На эпохе 32 параметры модели были сохранены при наилучшем значении функции потерь 0.333084 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8819.\n",
      "Epoch: 33\n",
      "Iter: 0 \tLoss: 0.29910725355148315\n",
      "Iter: 10 \tLoss: 0.32636895775794983\n",
      "Iter: 20 \tLoss: 0.2676616609096527\n",
      "Iter: 30 \tLoss: 0.29953905940055847\n",
      "Iter: 40 \tLoss: 0.30382049083709717\n",
      "Iter: 50 \tLoss: 0.26547133922576904\n",
      "Iter: 60 \tLoss: 0.25147655606269836\n",
      "Iter: 70 \tLoss: 0.27523720264434814\n",
      "Iter: 80 \tLoss: 0.2924163341522217\n",
      "Iter: 90 \tLoss: 0.29655715823173523\n",
      "Iter: 100 \tLoss: 0.2992919087409973\n",
      "Iter: 110 \tLoss: 0.20232483744621277\n",
      "Mean Train Loss: 0.286060\n",
      "\n",
      "Epoch: 34\n",
      "Iter: 0 \tLoss: 0.29055485129356384\n",
      "Iter: 10 \tLoss: 0.2918200194835663\n",
      "Iter: 20 \tLoss: 0.2885705232620239\n",
      "Iter: 30 \tLoss: 0.27551981806755066\n",
      "Iter: 40 \tLoss: 0.2907266914844513\n",
      "Iter: 50 \tLoss: 0.28225240111351013\n",
      "Iter: 60 \tLoss: 0.2572469115257263\n",
      "Iter: 70 \tLoss: 0.28488701581954956\n",
      "Iter: 80 \tLoss: 0.2675228416919708\n",
      "Iter: 90 \tLoss: 0.3056449890136719\n",
      "Iter: 100 \tLoss: 0.30745184421539307\n",
      "Iter: 110 \tLoss: 0.2583591938018799\n",
      "Mean Train Loss: 0.282385\n",
      "\n",
      "На эпохе 34 параметры модели были сохранены при наилучшем значении функции потерь 0.332430 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8840.\n",
      "Epoch: 35\n",
      "Iter: 0 \tLoss: 0.31836673617362976\n",
      "Iter: 10 \tLoss: 0.26070448756217957\n",
      "Iter: 20 \tLoss: 0.2563551366329193\n",
      "Iter: 30 \tLoss: 0.2969905138015747\n",
      "Iter: 40 \tLoss: 0.2716107666492462\n",
      "Iter: 50 \tLoss: 0.2805173993110657\n",
      "Iter: 60 \tLoss: 0.2979416251182556\n",
      "Iter: 70 \tLoss: 0.3057267665863037\n",
      "Iter: 80 \tLoss: 0.2559197247028351\n",
      "Iter: 90 \tLoss: 0.28326496481895447\n",
      "Iter: 100 \tLoss: 0.2741295397281647\n",
      "Iter: 110 \tLoss: 0.2310144603252411\n",
      "Mean Train Loss: 0.278882\n",
      "\n",
      "Epoch: 36\n",
      "Iter: 0 \tLoss: 0.26175713539123535\n",
      "Iter: 10 \tLoss: 0.2851191461086273\n",
      "Iter: 20 \tLoss: 0.23810431361198425\n",
      "Iter: 30 \tLoss: 0.26516619324684143\n",
      "Iter: 40 \tLoss: 0.28835663199424744\n",
      "Iter: 50 \tLoss: 0.27387261390686035\n",
      "Iter: 60 \tLoss: 0.29694506525993347\n",
      "Iter: 70 \tLoss: 0.24390234053134918\n",
      "Iter: 80 \tLoss: 0.28294244408607483\n",
      "Iter: 90 \tLoss: 0.22162151336669922\n",
      "Iter: 100 \tLoss: 0.3122832179069519\n",
      "Iter: 110 \tLoss: 0.26451748609542847\n",
      "Mean Train Loss: 0.275458\n",
      "\n",
      "На эпохе 36 параметры модели были сохранены при наилучшем значении функции потерь 0.329542 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8834.\n",
      "Epoch: 37\n",
      "Iter: 0 \tLoss: 0.2901947498321533\n",
      "Iter: 10 \tLoss: 0.2390187531709671\n",
      "Iter: 20 \tLoss: 0.31011369824409485\n",
      "Iter: 30 \tLoss: 0.25328508019447327\n",
      "Iter: 40 \tLoss: 0.2803391218185425\n",
      "Iter: 50 \tLoss: 0.27923884987831116\n",
      "Iter: 60 \tLoss: 0.2616908848285675\n",
      "Iter: 70 \tLoss: 0.2704997658729553\n",
      "Iter: 80 \tLoss: 0.21880175173282623\n",
      "Iter: 90 \tLoss: 0.3142335116863251\n",
      "Iter: 100 \tLoss: 0.25751304626464844\n",
      "Iter: 110 \tLoss: 0.23238225281238556\n",
      "Mean Train Loss: 0.273360\n",
      "\n",
      "Epoch: 38\n",
      "Iter: 0 \tLoss: 0.261125773191452\n",
      "Iter: 10 \tLoss: 0.2568562924861908\n",
      "Iter: 20 \tLoss: 0.2533387839794159\n",
      "Iter: 30 \tLoss: 0.23734676837921143\n",
      "Iter: 40 \tLoss: 0.25410744547843933\n",
      "Iter: 50 \tLoss: 0.25615909695625305\n",
      "Iter: 60 \tLoss: 0.26163530349731445\n",
      "Iter: 70 \tLoss: 0.25753432512283325\n",
      "Iter: 80 \tLoss: 0.2825303077697754\n",
      "Iter: 90 \tLoss: 0.25388243794441223\n",
      "Iter: 100 \tLoss: 0.26961567997932434\n",
      "Iter: 110 \tLoss: 0.2754027247428894\n",
      "Mean Train Loss: 0.269741\n",
      "\n",
      "На эпохе 38 параметры модели были сохранены при наилучшем значении функции потерь 0.331036 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8826.\n",
      "Epoch: 39\n",
      "Iter: 0 \tLoss: 0.2547553777694702\n",
      "Iter: 10 \tLoss: 0.26929768919944763\n",
      "Iter: 20 \tLoss: 0.2515515983104706\n",
      "Iter: 30 \tLoss: 0.24671782553195953\n",
      "Iter: 40 \tLoss: 0.28196489810943604\n",
      "Iter: 50 \tLoss: 0.27632927894592285\n",
      "Iter: 60 \tLoss: 0.28352609276771545\n",
      "Iter: 70 \tLoss: 0.24652715027332306\n",
      "Iter: 80 \tLoss: 0.3005701005458832\n",
      "Iter: 90 \tLoss: 0.23892684280872345\n",
      "Iter: 100 \tLoss: 0.3218750059604645\n",
      "Iter: 110 \tLoss: 0.2427433282136917\n",
      "Mean Train Loss: 0.266188\n",
      "\n",
      "Epoch: 40\n",
      "Iter: 0 \tLoss: 0.24303418397903442\n",
      "Iter: 10 \tLoss: 0.2884666919708252\n",
      "Iter: 20 \tLoss: 0.2655782103538513\n",
      "Iter: 30 \tLoss: 0.2484460175037384\n",
      "Iter: 40 \tLoss: 0.25553733110427856\n",
      "Iter: 50 \tLoss: 0.2589541971683502\n",
      "Iter: 60 \tLoss: 0.24946869909763336\n",
      "Iter: 70 \tLoss: 0.27524667978286743\n",
      "Iter: 80 \tLoss: 0.26446667313575745\n",
      "Iter: 90 \tLoss: 0.23838263750076294\n",
      "Iter: 100 \tLoss: 0.24966943264007568\n",
      "Iter: 110 \tLoss: 0.26835688948631287\n",
      "Mean Train Loss: 0.261982\n",
      "\n",
      "На эпохе 40 параметры модели были сохранены при наилучшем значении функции потерь 0.327119 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8839.\n",
      "Epoch: 41\n",
      "Iter: 0 \tLoss: 0.2799328863620758\n",
      "Iter: 10 \tLoss: 0.2821590006351471\n",
      "Iter: 20 \tLoss: 0.252115398645401\n",
      "Iter: 30 \tLoss: 0.23153196275234222\n",
      "Iter: 40 \tLoss: 0.29452839493751526\n",
      "Iter: 50 \tLoss: 0.24001584947109222\n",
      "Iter: 60 \tLoss: 0.26508867740631104\n",
      "Iter: 70 \tLoss: 0.23104816675186157\n",
      "Iter: 80 \tLoss: 0.2495974451303482\n",
      "Iter: 90 \tLoss: 0.25112083554267883\n",
      "Iter: 100 \tLoss: 0.2903427481651306\n",
      "Iter: 110 \tLoss: 0.2692427635192871\n",
      "Mean Train Loss: 0.258994\n",
      "\n",
      "Epoch: 42\n",
      "Iter: 0 \tLoss: 0.25674042105674744\n",
      "Iter: 10 \tLoss: 0.2655061185359955\n",
      "Iter: 20 \tLoss: 0.24979399144649506\n",
      "Iter: 30 \tLoss: 0.28906041383743286\n",
      "Iter: 40 \tLoss: 0.2920859158039093\n",
      "Iter: 50 \tLoss: 0.27743029594421387\n",
      "Iter: 60 \tLoss: 0.24100394546985626\n",
      "Iter: 70 \tLoss: 0.24662978947162628\n",
      "Iter: 80 \tLoss: 0.2723682224750519\n",
      "Iter: 90 \tLoss: 0.28729021549224854\n",
      "Iter: 100 \tLoss: 0.2409788966178894\n",
      "Iter: 110 \tLoss: 0.2513173520565033\n",
      "Mean Train Loss: 0.257749\n",
      "\n",
      "На эпохе 42 параметры модели были сохранены при наилучшем значении функции потерь 0.327516 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8855.\n",
      "Epoch: 43\n",
      "Iter: 0 \tLoss: 0.24649852514266968\n",
      "Iter: 10 \tLoss: 0.2508017420768738\n",
      "Iter: 20 \tLoss: 0.27541857957839966\n",
      "Iter: 30 \tLoss: 0.2572726309299469\n",
      "Iter: 40 \tLoss: 0.24850399792194366\n",
      "Iter: 50 \tLoss: 0.24122348427772522\n",
      "Iter: 60 \tLoss: 0.25024890899658203\n",
      "Iter: 70 \tLoss: 0.2547805905342102\n",
      "Iter: 80 \tLoss: 0.25884461402893066\n",
      "Iter: 90 \tLoss: 0.23451878130435944\n",
      "Iter: 100 \tLoss: 0.23124971985816956\n",
      "Iter: 110 \tLoss: 0.26310598850250244\n",
      "Mean Train Loss: 0.254119\n",
      "\n",
      "Epoch: 44\n",
      "Iter: 0 \tLoss: 0.24947607517242432\n",
      "Iter: 10 \tLoss: 0.29019296169281006\n",
      "Iter: 20 \tLoss: 0.23505373299121857\n",
      "Iter: 30 \tLoss: 0.2357446551322937\n",
      "Iter: 40 \tLoss: 0.2777669429779053\n",
      "Iter: 50 \tLoss: 0.250781387090683\n",
      "Iter: 60 \tLoss: 0.23571203649044037\n",
      "Iter: 70 \tLoss: 0.24909108877182007\n",
      "Iter: 80 \tLoss: 0.25935909152030945\n",
      "Iter: 90 \tLoss: 0.27881717681884766\n",
      "Iter: 100 \tLoss: 0.25778934359550476\n",
      "Iter: 110 \tLoss: 0.3302115797996521\n",
      "Mean Train Loss: 0.251531\n",
      "\n",
      "На эпохе 44 параметры модели были сохранены при наилучшем значении функции потерь 0.326127 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8868.\n",
      "Epoch: 45\n",
      "Iter: 0 \tLoss: 0.25198110938072205\n",
      "Iter: 10 \tLoss: 0.21078884601593018\n",
      "Iter: 20 \tLoss: 0.23364746570587158\n",
      "Iter: 30 \tLoss: 0.25897616147994995\n",
      "Iter: 40 \tLoss: 0.2770310342311859\n",
      "Iter: 50 \tLoss: 0.25281810760498047\n",
      "Iter: 60 \tLoss: 0.2373991310596466\n",
      "Iter: 70 \tLoss: 0.2372264266014099\n",
      "Iter: 80 \tLoss: 0.28437545895576477\n",
      "Iter: 90 \tLoss: 0.22588208317756653\n",
      "Iter: 100 \tLoss: 0.22862499952316284\n",
      "Iter: 110 \tLoss: 0.3989039659500122\n",
      "Mean Train Loss: 0.248783\n",
      "\n",
      "Epoch: 46\n",
      "Iter: 0 \tLoss: 0.2482687532901764\n",
      "Iter: 10 \tLoss: 0.2407355010509491\n",
      "Iter: 20 \tLoss: 0.22928427159786224\n",
      "Iter: 30 \tLoss: 0.2393314242362976\n",
      "Iter: 40 \tLoss: 0.25829628109931946\n",
      "Iter: 50 \tLoss: 0.24700705707073212\n",
      "Iter: 60 \tLoss: 0.2507462203502655\n",
      "Iter: 70 \tLoss: 0.23048165440559387\n",
      "Iter: 80 \tLoss: 0.21522538363933563\n",
      "Iter: 90 \tLoss: 0.2739996016025543\n",
      "Iter: 100 \tLoss: 0.28187790513038635\n",
      "Iter: 110 \tLoss: 0.28987282514572144\n",
      "Mean Train Loss: 0.245848\n",
      "\n",
      "На эпохе 46 параметры модели были сохранены при наилучшем значении функции потерь 0.323537 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8882.\n",
      "Epoch: 47\n",
      "Iter: 0 \tLoss: 0.2569954991340637\n",
      "Iter: 10 \tLoss: 0.22998090088367462\n",
      "Iter: 20 \tLoss: 0.26505380868911743\n",
      "Iter: 30 \tLoss: 0.24135585129261017\n",
      "Iter: 40 \tLoss: 0.20628446340560913\n",
      "Iter: 50 \tLoss: 0.21998319029808044\n",
      "Iter: 60 \tLoss: 0.25183558464050293\n",
      "Iter: 70 \tLoss: 0.2585223615169525\n",
      "Iter: 80 \tLoss: 0.23963749408721924\n",
      "Iter: 90 \tLoss: 0.24341778457164764\n",
      "Iter: 100 \tLoss: 0.27730095386505127\n",
      "Iter: 110 \tLoss: 0.19425806403160095\n",
      "Mean Train Loss: 0.242528\n",
      "\n",
      "Epoch: 48\n",
      "Iter: 0 \tLoss: 0.216506689786911\n",
      "Iter: 10 \tLoss: 0.2541091740131378\n",
      "Iter: 20 \tLoss: 0.24938073754310608\n",
      "Iter: 30 \tLoss: 0.26895418763160706\n",
      "Iter: 40 \tLoss: 0.2553692162036896\n",
      "Iter: 50 \tLoss: 0.26626908779144287\n",
      "Iter: 60 \tLoss: 0.23513858020305634\n",
      "Iter: 70 \tLoss: 0.24642521142959595\n",
      "Iter: 80 \tLoss: 0.2546060383319855\n",
      "Iter: 90 \tLoss: 0.2351136952638626\n",
      "Iter: 100 \tLoss: 0.2532595694065094\n",
      "Iter: 110 \tLoss: 0.16947922110557556\n",
      "Mean Train Loss: 0.239203\n",
      "\n",
      "На эпохе 48 параметры модели были сохранены при наилучшем значении функции потерь 0.325843 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8880.\n",
      "Epoch: 49\n",
      "Iter: 0 \tLoss: 0.2509310245513916\n",
      "Iter: 10 \tLoss: 0.20783638954162598\n",
      "Iter: 20 \tLoss: 0.19568517804145813\n",
      "Iter: 30 \tLoss: 0.2529889941215515\n",
      "Iter: 40 \tLoss: 0.23336324095726013\n",
      "Iter: 50 \tLoss: 0.24036149680614471\n",
      "Iter: 60 \tLoss: 0.21484272181987762\n",
      "Iter: 70 \tLoss: 0.244833841919899\n",
      "Iter: 80 \tLoss: 0.2279873788356781\n",
      "Iter: 90 \tLoss: 0.26228392124176025\n",
      "Iter: 100 \tLoss: 0.25214630365371704\n",
      "Iter: 110 \tLoss: 0.21789494156837463\n",
      "Mean Train Loss: 0.235526\n",
      "\n",
      "Epoch: 50\n",
      "Iter: 0 \tLoss: 0.2379937469959259\n",
      "Iter: 10 \tLoss: 0.1941545605659485\n",
      "Iter: 20 \tLoss: 0.2629753649234772\n",
      "Iter: 30 \tLoss: 0.23157735168933868\n",
      "Iter: 40 \tLoss: 0.23602579534053802\n",
      "Iter: 50 \tLoss: 0.23153343796730042\n",
      "Iter: 60 \tLoss: 0.24160316586494446\n",
      "Iter: 70 \tLoss: 0.26849743723869324\n",
      "Iter: 80 \tLoss: 0.24802036583423615\n",
      "Iter: 90 \tLoss: 0.23473332822322845\n",
      "Iter: 100 \tLoss: 0.22519448399543762\n",
      "Iter: 110 \tLoss: 0.2321937084197998\n",
      "Mean Train Loss: 0.235111\n",
      "\n",
      "На эпохе 50 параметры модели были сохранены при наилучшем значении функции потерь 0.325200 на валидационной выборке.\n",
      "Метрика Accuracy: 0.8856.\n"
     ]
    }
   ],
   "source": [
    "train(clf, opt, loss_fn, train_loader, val_loader, n_epoch, val_fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539bed8-002f-4cc1-bed0-607f05033175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
